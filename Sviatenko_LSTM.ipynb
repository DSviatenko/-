{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Задані тексти\n",
        "texts_true = [\n",
        "    \"Після релізу додатку, наша компанія отримала дуже позитивну оцінку.\",\n",
        "    \"Користувачі були задоволені.\"\n",
        "    \"Цей сервіс отримав ще один позитивний відгук.\"\n",
        "]\n",
        "\n",
        "texts_false = [\n",
        "    \"Компанія отримала негативний досвід.\",\n",
        "    \"Додаток не досягнув очікуваного успіху.\",\n",
        "    \"Оцінка компанії була негативна.\"\n",
        "]\n",
        "\n",
        "# Об'єднання текстів\n",
        "texts = texts_true + texts_false\n",
        "count_true = len(texts_true)\n",
        "count_false = len(texts_false)\n",
        "total_lines = count_true + count_false\n",
        "print(count_true, count_false, total_lines)\n",
        "\n",
        "maxWordsCount = 1000\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»', lower=True, split=' ', char_level=False)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "dist = list(tokenizer.word_counts.items())\n",
        "print(dist[:10])\n",
        "print(texts[0][:100])\n",
        "\n",
        "max_text_len = 10\n",
        "data = tokenizer.texts_to_sequences(texts)\n",
        "data_pad = pad_sequences(data, maxlen=max_text_len)\n",
        "print(data_pad)\n",
        "\n",
        "print(list(tokenizer.word_index.items()))\n",
        "\n",
        "X = data_pad\n",
        "Y = np.array([[1, 0]]*count_true + [[0, 1]]*count_false)\n",
        "print(X.shape, Y.shape)\n",
        "\n",
        "indices = np.random.choice(X.shape[0], size=X.shape[0], replace=False)\n",
        "X = X[indices]\n",
        "Y = Y[indices]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(maxWordsCount, 128, input_length=max_text_len))\n",
        "model.add(LSTM(128, return_sequences=True, activation='relu'))  \n",
        "model.add(LSTM(64, activation='tanh'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=RMSprop(learning_rate=0.001))\n",
        "\n",
        "history = model.fit(X, Y, batch_size=32, epochs=50)\n",
        "\n",
        "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
        "\n",
        "def sequence_to_text(list_of_indices):\n",
        "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
        "    return(words)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2 3 5\n[('після', 1), ('релізу', 1), ('додатку', 1), ('наша', 1), ('компанія', 2), ('отримала', 2), ('дуже', 1), ('позитивну', 1), ('оцінку', 1), ('користувачі', 1)]\nПісля релізу додатку, наша компанія отримала дуже позитивну оцінку.\n[[ 0  3  4  5  6  1  2  7  8  9]\n [10 11 12 13 14 15 16 17 18 19]\n [ 0  0  0  0  0  0  1  2 20 21]\n [ 0  0  0  0  0 22 23 24 25 26]\n [ 0  0  0  0  0  0 27 28 29 30]]\n[('компанія', 1), ('отримала', 2), ('після', 3), ('релізу', 4), ('додатку', 5), ('наша', 6), ('дуже', 7), ('позитивну', 8), ('оцінку', 9), ('користувачі', 10), ('були', 11), ('задоволені', 12), ('цей', 13), ('сервіс', 14), ('отримав', 15), ('ще', 16), ('один', 17), ('позитивний', 18), ('відгук', 19), ('негативний', 20), ('досвід', 21), ('додаток', 22), ('не', 23), ('досягнув', 24), ('очікуваного', 25), ('успіху', 26), ('оцінка', 27), ('компанії', 28), ('була', 29), ('негативна', 30)]\n(5, 10) (5, 2)\nModel: \"sequential_7\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_7 (Embedding)     (None, 10, 128)           128000    \n                                                                 \n lstm_7 (LSTM)               (None, 10, 128)           131584    \n                                                                 \n lstm_8 (LSTM)               (None, 64)                49408     \n                                                                 \n dense_13 (Dense)            (None, 2)                 130       \n                                                                 \n=================================================================\nTotal params: 309122 (1.18 MB)\nTrainable params: 309122 (1.18 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\nEpoch 1/50\n1/1 [==============================] - 2s 2s/step - loss: 0.6920 - accuracy: 0.6000\nEpoch 2/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.6738 - accuracy: 0.6000\nEpoch 3/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.6556 - accuracy: 0.6000\nEpoch 4/50\n1/1 [==============================] - 0s 10ms/step - loss: 0.6306 - accuracy: 0.6000\nEpoch 5/50\n1/1 [==============================] - 0s 10ms/step - loss: 0.5937 - accuracy: 0.6000\nEpoch 6/50\n1/1 [==============================] - 0s 10ms/step - loss: 0.5404 - accuracy: 0.6000\nEpoch 7/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.4698 - accuracy: 0.8000\nEpoch 8/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.3860 - accuracy: 0.8000\nEpoch 9/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.2999 - accuracy: 1.0000\nEpoch 10/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.2218 - accuracy: 1.0000\nEpoch 11/50\n1/1 [==============================] - 0s 8ms/step - loss: 0.1549 - accuracy: 1.0000\nEpoch 12/50\n1/1 [==============================] - 0s 10ms/step - loss: 0.1030 - accuracy: 1.0000\nEpoch 13/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.0675 - accuracy: 1.0000\nEpoch 14/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.0458 - accuracy: 1.0000\nEpoch 15/50\n1/1 [==============================] - 0s 10ms/step - loss: 0.0328 - accuracy: 1.0000\nEpoch 16/50\n1/1 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 1.0000\nEpoch 17/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.0195 - accuracy: 1.0000\nEpoch 18/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.0159 - accuracy: 1.0000\nEpoch 19/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.0132 - accuracy: 1.0000\nEpoch 20/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.0113 - accuracy: 1.0000\nEpoch 21/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.0098 - accuracy: 1.0000\nEpoch 22/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 1.0000\nEpoch 23/50\n1/1 [==============================] - 0s 10ms/step - loss: 0.0076 - accuracy: 1.0000\nEpoch 24/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 1.0000\nEpoch 25/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.0061 - accuracy: 1.0000\nEpoch 26/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 1.0000\nEpoch 27/50\n1/1 [==============================] - 0s 10ms/step - loss: 0.0051 - accuracy: 1.0000\nEpoch 28/50\n1/1 [==============================] - 0s 13ms/step - loss: 0.0047 - accuracy: 1.0000\nEpoch 29/50\n1/1 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 1.0000\nEpoch 30/50\n1/1 [==============================] - 0s 12ms/step - loss: 0.0040 - accuracy: 1.0000\nEpoch 31/50\n1/1 [==============================] - 0s 11ms/step - loss: 0.0037 - accuracy: 1.0000\nEpoch 32/50\n1/1 [==============================] - 0s 11ms/step - loss: 0.0034 - accuracy: 1.0000\nEpoch 33/50\n1/1 [==============================] - 0s 12ms/step - loss: 0.0032 - accuracy: 1.0000\nEpoch 34/50\n1/1 [==============================] - 0s 12ms/step - loss: 0.0030 - accuracy: 1.0000\nEpoch 35/50\n1/1 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000\nEpoch 36/50\n1/1 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 1.0000\nEpoch 37/50\n1/1 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 1.0000\nEpoch 38/50\n1/1 [==============================] - 0s 11ms/step - loss: 0.0023 - accuracy: 1.0000\nEpoch 39/50\n1/1 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 1.0000\nEpoch 40/50\n1/1 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 1.0000\nEpoch 41/50\n1/1 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000\nEpoch 42/50\n1/1 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000\nEpoch 43/50\n1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000\nEpoch 44/50\n1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000\nEpoch 45/50\n1/1 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000\nEpoch 46/50\n1/1 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 1.0000\nEpoch 47/50\n1/1 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000\nEpoch 48/50\n1/1 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000\nEpoch 49/50\n1/1 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000\nEpoch 50/50\n1/1 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000\n"
        }
      ],
      "execution_count": 61,
      "metadata": {
        "tags": []
      },
      "id": "77a51b67-344a-4218-87a7-08b063cff2b0"
    },
    {
      "cell_type": "code",
      "source": [
        "t = \"Наша компанія отримала позитивну новину.\".lower()\n",
        "data = tokenizer.texts_to_sequences([t])\n",
        "data_pad = pad_sequences(data, maxlen=max_text_len)\n",
        "print( sequence_to_text(data[0]) )\n",
        "\n",
        "res = model.predict(data_pad)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['наша', 'компанія', 'отримала', 'позитивну']\n1/1 [==============================] - 0s 370ms/step\n"
        }
      ],
      "execution_count": 62,
      "metadata": {},
      "id": "1fc1cf87-d509-4860-a2d3-77da92c5aac0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Визначення результату\n",
        "if np.argmax(res) == 1:\n",
        "    print(\"Результат. Текст позитивний.\")\n",
        "else:\n",
        "    print(\"Результат. Текст негативний.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Результат. Текст позитивний.\n"
        }
      ],
      "execution_count": 67,
      "metadata": {},
      "id": "e04a8a44"
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = \"Досвід був негативний\".lower()\n",
        "data1 = tokenizer.texts_to_sequences([t1])\n",
        "data_pad1 = pad_sequences(data1, maxlen=max_text_len)\n",
        "print( sequence_to_text(data1[0]) )\n",
        "\n",
        "res1 = model.predict(data_pad1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['досвід', 'негативний']\n1/1 [==============================] - 0s 16ms/step\n"
        }
      ],
      "execution_count": 64,
      "metadata": {},
      "id": "48015c80"
    },
    {
      "cell_type": "code",
      "source": [
        "# Визначення результату\n",
        "if np.argmax(res1) == 0:\n",
        "    print(\"Результат. Текст позитивний.\")\n",
        "else:\n",
        "    print(\"Результат. Текст негативний.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Результат. Текст позитивний.\n"
        }
      ],
      "execution_count": 68,
      "metadata": {},
      "id": "febe4627"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Висновок:** на лабораторній роботі я навчився створювати архітектуру рекурентної нейронної мережі для семантичного аналізу з використанням моделі LSTM."
      ],
      "metadata": {},
      "id": "ceea5775"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "dc3fbf9a"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python",
      "language": "python",
      "display_name": "Pyolite (preview)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernel_info": {
      "name": "python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}